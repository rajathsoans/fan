{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> How to apply Feature Aware Normalization to a novel dataset </h1>\n",
    "</center>\n",
    "<center>\n",
    "Steffen Schneider and Daniel Bug <br />\n",
    "Institute of Imaging & Computer Vision <br />\n",
    "steffen.schneider@rwth-aachen.de\n",
    "</center>\n",
    "\n",
    "\n",
    "In this tutorial, we will demonstrate the feature aware normalization module [1] on the digital pathology dataset by [2,3]. Details on the approach are available in our [paper](https://arxiv.org/abs/1708.04099) as well as on the [project page](https://stes.github.io/fan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this code in your research, please cite our [paper](https://arxiv.org/abs/1708.04099):\n",
    "\n",
    "```\n",
    "@incollection{bug2017context,\n",
    "  title={Context-based Normalization of Histological Stains using Deep Convolutional Features},\n",
    "  author={Bug, Daniel and Schneider, Steffen and Grote, Anne and Oswald, Eva and Feuerhake, Friedrich and Sch{\\\"u}ler, Julia and Merhof, Dorit},\n",
    "  booktitle={Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},\n",
    "  pages={135--142},\n",
    "  year={2017},\n",
    "  publisher={Springer}\n",
    "}\n",
    "```\n",
    "\n",
    "We also have a pre-print available on arxiv: [abs/1708.04099](https://arxiv.org/abs/1708.04099)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Feature Aware Normalization is a technique for normalizing images based on context information estimated by a Feature Extraction Network.\n",
    "Instead of normal batch normalization layers, in FAN, the shift and scaling parameters $\\beta$ and $\\gamma$ are functions of a feature representation $z$ computed from the input image.\n",
    "\n",
    "![Unnormalized Images](docs/img/BAS_unnormalized_A.jpg)\n",
    "![FAN normalized Images](docs/img/FAN_HoEoTp_A.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Network weights\n",
    "\n",
    "In this tutorial, we will use the public available dataset of Kather et al. (2016).\n",
    "\n",
    "The data is licensed under the [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
    "The data can be accessed via the following DOI: [10.5281/zenodo.53169.](dx.doi.org/10.5281/zenodo.53169)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset, 5000 patches with resolution 150x150 (258.1 MB)\n",
    "#!wget https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip\n",
    "# MD5SUM 0ddbebfc56344752028fda72602aaade\n",
    "\n",
    "# Validation dataset, 10 patches with resolution 5000x5000 (742.0 MB)\n",
    "# !wget https://zenodo.org/record/53169/files/Kather_texture_2016_larger_images_10.zip\n",
    "# MD5SUM ff6e18f484c5d324b049ed2ec133d9cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrety check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cd data && md5sum --check MD5SUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip -qq -o data/Kather_texture_2016_image_tiles_5000.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the network weights\n",
    "\n",
    "We will need both the weights for the feature extactor (defaults to the VGG19 network) and the normalization network. The latter was trained as outlined in our original publication [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! cd weights && wget \"https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg19_normalized.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrety check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check file\n",
    "! echo \"cb8ee699c50a64f8fef2a82bfbb307c5  weights/vgg19_normalized.pkl\" | md5sum --check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization with FAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "from tifffile import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"data/Kather_texture_2016_image_tiles_5000\"\n",
    "assert os.path.exists(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_small_patches(root):\n",
    "    classes = os.listdir(root)\n",
    "    X     = []\n",
    "    y     = []\n",
    "    lbl   = []\n",
    "    fnames = []\n",
    "    \n",
    "    for i, cl in enumerate(sorted(classes)):\n",
    "        classdir = os.path.join(root, cl)\n",
    "        if not os.path.isdir(classdir): continue\n",
    "        imgfiles = os.listdir(classdir)\n",
    "        \n",
    "        for j, fname in enumerate(imgfiles):\n",
    "            path = os.path.join(root, cl, fname)\n",
    "            X.append(imread(path))\n",
    "            y.append(i)\n",
    "            fnames.append(path)\n",
    "        lbl.append(cl)\n",
    "        \n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.stack(y, axis=0)\n",
    "    \n",
    "    return X, y, lbl, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, lbl, fnames = load_small_patches(root)\n",
    "print(\"Loaded {} images of size {}x{}\".format(*X.shape[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stainnorm import fan\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fan.NormalizationNetwork(fname='weights/171028-weights-dlmia.npz',\n",
    "                                patch_size=300,\n",
    "                                batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormed = model.crop(X[100:103].repeat(2,axis=1).repeat(2,axis=2))\n",
    "normed = model(X[100:103].repeat(2,axis=1).repeat(2,axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [ X[y == 3].max(axis=(1,2)),\n",
    "           X[y == 3].min(axis=(1,2)),\n",
    "           X[y == 3].mean(axis=(1,2)),\n",
    "           X[y == 3].std(axis=(1,2)) ]\n",
    "\n",
    "colors = np.concatenate(colors, axis=-1)\n",
    "colors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing\n",
    "\n",
    "We'll preprocess the dataset for visualization purposes. Patches are labeled according to eight different classes.\n",
    "For purposes of comparison, we'll employ a very simple clustering scheme based on the average value of the RGB channels to estimate the protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "embedding = tsne.fit_transform(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:,0], embedding[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(10)\n",
    "gmm.fit(embedding)\n",
    "yd = gmm.predict(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:,0], embedding[:,1], c=yd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from stainnorm.tools import panelize\n",
    "from itertools import product\n",
    "\n",
    "overview = np.zeros((10,10)+X.shape[1:])\n",
    "\n",
    "for i in range(overview.shape[0]):\n",
    "    for j in range(overview.shape[1]):\n",
    "        x = X[y == 3][yd == j]\n",
    "        if len(x) > i:     \n",
    "            overview[i,j,...] = x[i]\n",
    "print(overview.shape)\n",
    "            \n",
    "grid = np.concatenate(np.concatenate(overview, axis=1), axis=1)\n",
    "print(grid.shape)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(grid / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed = []\n",
    "for batch in overview.transpose((1,0,2,3,4)):\n",
    "    normed.append(model(batch.repeat(2,axis=1).repeat(2,axis=2)))\n",
    "    print(\"finsished\")\n",
    "    \n",
    "normed = np.stack(normed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed.shape, overview.shape\n",
    "\n",
    "grid = np.concatenate(np.concatenate(normed, axis=1), axis=1)\n",
    "print(grid.shape)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(grid / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed.shape\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for u, n in zip(unnormed, normed):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "    ax1.imshow(u/255.)\n",
    "    ax2.imshow(n/255.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "\n",
    "1. Bug et al.\n",
    "2. Kather, Jakob Nikolas, et al. \"Multi-class texture analysis in colorectal cancer histology.\" Scientific reports 6 (2016): 27988. DOI [10.1038/srep27988](https://dx.doi.org/10.1038/srep27988)\n",
    "3. Kather, Jakob Nikolas, et al. \"Collection of textures in colorectal cancer histology, May 2016.\" Last Accessed 19 (2016). DOI [10.5281/zenodo.53169](https://dx.doi.org/10.5281/zenodo.53169)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
